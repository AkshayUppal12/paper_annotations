<img src='https://imgur.com/9qkTE8Z.png'>

A place to keep track of all the annotated papers.

- ðŸ“« How to reach me **[@akshayuppal12](https://twitter.com/akshayuppal12)**
- ðŸ“„ Know about my experiences on [LinkedIn](https://www.linkedin.com/in/uppalakshay/)
- Check out mt blog for such papers, tutorials and more: [https://au1206.github.io/](https://au1206.github.io/)

---
## Papers
| | Paper | Conference | Year |
| :---: | :--- | :---: | :---: |
|1.| [PICK : Processing Key Information Extraction from Documents using Improved Graph Learning-Convolutional Networks](https://github.com/au1206/paper_annotations/blob/master/PICK.pdf)|ICPR |2020|
|2.| [Attention is All you Need](https://github.com/au1206/paper_annotations/blob/master/attention_is_all_you_need.pdf) | NeurIPS |2017 |
|3.| [MLP-Mixer: An all MLP Architecture for Vision](https://github.com/au1206/paper_annotations/blob/master/mlp_mixer.pdf)| CVPR|May 2021|
|4.| [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://github.com/au1206/paper_annotations/blob/master/BERT.pdf)|NAACL 19|2018|
|5.| [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://github.com/au1206/paper_annotations/blob/master/EfficientNet.pdf)| ICML|2019|
|6.| [EfficientNetV2: Smaller Models and Faster Training](https://github.com/au1206/paper_annotations/blob/master/EfficientNet-v2.pdf) | ICML |2021|
|7.| [Few-Shot Named Entity Recognition: A Comprehensive Study](https://github.com/au1206/paper_annotations/blob/master/Few_shot_NER.pdf) | |Dec 2020|
|8.| [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://github.com/au1206/paper_annotations/blob/master/RoBERTa.pdf)| |Jul 2019 |


---
## Sample Annotations
<img src="https://imgur.com/v1TnohA.gif" width='600'>


## Color Scheme
| Color | Meaning |
| :---: | :--- | 
| Green | Topics about the current paper |
| Yellow | Topics about other relevant references |
| Blue | Implementation details/ maths/experiments |
| Red | Text including my thoughts, questions, and understandings | 
---



